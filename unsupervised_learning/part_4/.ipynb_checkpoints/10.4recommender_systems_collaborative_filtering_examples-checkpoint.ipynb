{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples: Recommender systems: Collaborative filtering\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will dive into collaborative filtering. Through practical implementation, we'll explore how collaborative filtering leverages user similarity to make personalised recommendations. We'll explore its implementation and compare it with content-based filtering to understand the trade-offs between the two approaches.\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you should be able to:\n",
    "* Gain intuition for the basic operation of collaborative filtering.\n",
    "* Implement a simple collaborative-based filtering algorithm.\n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "This train is structured as follows:\n",
    "- The intuition behind collaborative-based filtering\n",
    "- Implementation of collaborative-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative-based Filtering "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 700px; font-size: 80%; text-align: center; margin-left: 80px\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Utility_Matrix.jpg\"\n",
    "     alt=\"Collaborative-based Filtering - Utility Matrix\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=700px/>\n",
    "Utility matrix used to assess the similarity between users who have rated items. \n",
    "</div>\n",
    "\n",
    "In content-based filtering, we looked at the similarity between the properties or attributes of items. In collaborative-based filtering, **we measure the similarity between users to make recommendations**.\n",
    "\n",
    "To see how this works, consider several individuals who are currently using our collaborative-based recommender system. Simon, Kwanda, Kieran and Joanne have all rated certain books that they've read, and we've been able to capture these results. Using this information, we can construct what is known as a **Utility Matrix**, which (as shown in the figure above) is a structure simply capturing our rating data in a formal way. In the utility matrix, each user is represented as a row$^*$, and the items (books) in our catalogue make up features for each user - whether they have rated a book or not, and what ratings they have given. We note here importantly that this matrix is inherently *sparse*, as there are far more items available in the catalogue than a user's supplied ratings.  \n",
    "\n",
    "Using the structured information in the utility matrix, we can measure how similar users are to one another based on their rating characteristics. Using our example to help make this point, consider how Joanne and Simon could be considered to be similar as both have read the novels \"Pride and Prejudice\" and \"The Diary of a Young Girl\", and have given very similar ratings for both. On the other hand, even though Kwanda has also read and similarly rated \"The Diary of a Young Girl\", he would still be considered less similar to a user like Simon as they have fewer book reviews in common. \n",
    "\n",
    "Using this principle of user similarity, when we seek to make a recommendation for a user based on collaborative filtering, we usually seek to determine the *k-neighbors* who are most similar to the user. From these users, we then extract their highly-rated items and use these as a basis for recommendations. \n",
    "\n",
    "One powerful argument of why using user similarity is favourable, compared to that of item similarity, lies in recommendation variety. When looking at our content-based recommendations, we observed that the items suggested tended to be homogeneous; they were all by the same author or genre etc. But humans aren't homogeneous all the time - we like different things in different categories and at different times. As collaborative filtering considers similar individuals, it also considers similarities across categories, allowing recommendations to be more varied and natural.\n",
    "\n",
    "A major downside to this approach, however, is described by what is known as the **'Cold-start problem'**. Consider, for example, user Kieran, who has just recently joined our recommender service. He has supplied only one rating; he seems to absolutely love \"The Hunger Games\". The problem is that no one else in our service has rated that book, and Kieran hasn't rated anything else as well. This predicament means that we cannot get a similarity between Kieran and any other user - making our collaborative approach infeasible! While there are various ways of getting around this problem (we see a simple example in our implementation), the Cold-start problem is an ongoing challenge which continues to haunt recommender system researchers. If you feel passionate about this field, perhaps you need to be the person to solve this problem definitively once and for all!\n",
    "\n",
    "$^*$*Note that this isn't always the case, as it's perfectly acceptable for the utility matrix to have rows representing items and columns representing users. The important thing is that we are mapping ratings from users to items in one form or another.*  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "\n",
    "Once again, we will be using the **Book_rating.csv** dataset derived from the [Goodbooks-10k dataset](http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/) within this train.\n",
    "\n",
    "As usua, we can start by importing the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our regular old heroes \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp # <-- The sister of Numpy, used in our code for numerical efficiency. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entity featurization and similarity computation\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Libraries used during sorting procedures.\n",
    "import operator # <-- Convenient item retrieval during iteration \n",
    "import heapq # <-- Efficient sorting of large lists\n",
    "\n",
    "# Imported for our sanity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratings = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/book_ratings.csv')\n",
    "book_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Number of ratings in dataset: {book_ratings.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation \n",
    "\n",
    "We now implement a simple collaborative filtering-based recommendation algorithm.\n",
    "\n",
    "In a similar process to content filtering, where we first had to gather item features before we could compute their similarity, within collaborative filtering, we initially needed to gather all user ratings together by forming a utility matrix.\n",
    "\n",
    "Using `pandas`, we can construct our utility matrix easily by using the `pivot_table` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_matrix = book_ratings.pivot_table(index=['user_id'], \n",
    "                                       columns=['title'],\n",
    "                                       values='rating') \n",
    "util_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously mentioned that the utility matrix is sparse, as it is unlikely that a user has read many of the books within the entire Goodbooks library. To illustrate this point, let's visualise a portion of the utility matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neat version of the utility matrix to assist with plotting book titles \n",
    "book_ratings['neat_title'] = book_ratings['title'].apply(lambda x: x[:20])\n",
    "util_matrix_neat = book_ratings.pivot_table(index=['user_id'], \n",
    "                                            columns=['neat_title'],\n",
    "                                            values='rating')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "# We select only the first 100 users for ease of computation and visualisation. \n",
    "# You can play around with this value to see more of the utility matrix. \n",
    "_ = sns.heatmap(util_matrix_neat[:100], annot=False, ax=ax).set_title('GoodBooks Utility Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the white regions of the heatmap indicate cells in the utility matrix for which we have no rating data. \n",
    "\n",
    "With our utility matrix created, we now preprocess our data in preparation for similarity computation. This is done by normalising each user's set of ratings, filling in Nan values with 0, [transposing](https://www.khanacademy.org/math/linear-algebra/matrix-transformations/matrix-transpose/v/linear-algebra-transpose-of-a-matrix) our matrix for easier indexing, dropping users with no ratings, and storing the matrix in a sparse representation to save memory.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each row (a given user's ratings) of the utility matrix\n",
    "util_matrix_norm = util_matrix.apply(lambda x: (x-np.mean(x))/(np.max(x)-np.min(x)), axis=1)\n",
    "# Fill Nan values with 0's, transpose matrix, and drop users with no ratings\n",
    "util_matrix_norm.fillna(0, inplace=True)\n",
    "util_matrix_norm = util_matrix_norm.T\n",
    "util_matrix_norm = util_matrix_norm.loc[:, (util_matrix_norm != 0).any(axis=0)]\n",
    "# Save the utility matrix in scipy's sparse matrix format\n",
    "util_matrix_sparse = sp.sparse.csr_matrix(util_matrix_norm.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the similarity between users based on the ratings they have given various books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the similarity matrix using the cosine similarity metric\n",
    "user_similarity = cosine_similarity(util_matrix_sparse.T)\n",
    "# Save the matrix as a dataframe to allow for easier indexing  \n",
    "user_sim_df = pd.DataFrame(user_similarity, \n",
    "                           index = util_matrix_norm.columns, \n",
    "                           columns = util_matrix_norm.columns)\n",
    "\n",
    "# Review a small portion of the constructed similarity matrix  \n",
    "user_sim_df[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our similarity matrix formed, we are once again in a position to make some recommendations. \n",
    "\n",
    "As was the process for content-based filtering, we'll first look at generating top-N recommendations and then rating predictions using collaborative filtering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-N Recommendations\n",
    "\n",
    "In order to produce a list of top-N recommendations for collaborative filtering, the following simple algorithm can be followed: \n",
    "\n",
    "  1. Select an initial reference user to generate recommendations for. \n",
    "  2. Extract all the similarity values between the reference user and each other user in the similarity matrix.\n",
    "  3. Sort the resulting similarity values in descending order, and select the $k$ most similar users based on these values.  \n",
    "  5. For each selected user, collect their top-rated items. \n",
    "  6. Form a tally of which items are most popular across the $k$ similar users. Do this by counting how many times a top-rated item is common amongst the other users. \n",
    "  7. Sort the top-rated items according to the popularity tally. Return the top-N values as the result. \n",
    "    \n",
    "  \n",
    "We implement this algorithmic process in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collab_generate_top_N_recommendations(user, N=10, k=20):\n",
    "    # Cold-start problem - no ratings given by the reference user. \n",
    "    # With no further user data, we solve this by simply recommending\n",
    "    # the top-N most popular books in the item catalogue. \n",
    "    if user not in user_sim_df.columns:\n",
    "        return book_ratings.groupby('title').mean().sort_values(by='rating',\n",
    "                                        ascending=False).index[:N].to_list()\n",
    "    \n",
    "    # Gather the k users which are most similar to the reference user \n",
    "    sim_users = user_sim_df.sort_values(by=user, ascending=False).index[1:k+1]\n",
    "    favorite_user_items = [] # <-- List of highest rated items gathered from the k users  \n",
    "    most_common_favorites = {} # <-- Dictionary of highest rated items in common for the k users\n",
    "    \n",
    "    for i in sim_users:\n",
    "        # Maximum rating given by the current user to an item \n",
    "        max_score = util_matrix_norm.loc[:, i].max()\n",
    "        # Save the names of items maximally rated by the current user   \n",
    "        favorite_user_items.append(util_matrix_norm[util_matrix_norm.loc[:, i]==max_score].index.tolist())\n",
    "        \n",
    "    # Loop over each user's favourite items and tally which ones are \n",
    "    # most popular overall.\n",
    "    for item_collection in range(len(favorite_user_items)):\n",
    "        for item in favorite_user_items[item_collection]: \n",
    "            if item in most_common_favorites:\n",
    "                most_common_favorites[item] += 1\n",
    "            else:\n",
    "                most_common_favorites[item] = 1\n",
    "    # Sort the overall most popular items and return the top-N instances\n",
    "    sorted_list = sorted(most_common_favorites.items(), key=operator.itemgetter(1), reverse=True)[:N]\n",
    "    top_N = [x[0] for x in sorted_list]\n",
    "    return top_N  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our algorithm defined, let's go and look at the recommended books for our friend, user 314:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our recommended list for user 314\n",
    "collab_generate_top_N_recommendations(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User 314's historical ratings\n",
    "book_ratings[book_ratings['user_id'] == 314][:][['title','rating']].sort_values(by='rating', ascending=False)[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In considering our recommended list and comparing it to that of user 314's actual favourite reads, several things stand out: \n",
    "\n",
    " - First, the list we have generated is far more diverse than those we produced via content-based filtering. Here, we recommend books which feel more similar in genre than, say, the author alone.\n",
    " \n",
    " \n",
    " - Second, there is an overlap between the titles that user 314 has already read and those produced by our list. This is actually understandable, as users who have rated the same content highly will be more similar to the reference user.\n",
    " \n",
    " \n",
    " - Third, our list's recommendations align well with user 314's preferences. Here highly rated books by the user appear in our recommended list. Just as mentioned for content-based filtering, the use of a metric such as the hit-rate could help quantify this good fit. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Prediction\n",
    "\n",
    "We can generate user-item ratings for collaborative filtering using the following algorithmic steps: \n",
    "\n",
    "   1. Select a reference user from the database and a reference item (book) they have _not_ rated. \n",
    "   2. For the reference user, gather the similarity values between them and each other user. \n",
    "   3. Sort the gathered similarity values in descending order. \n",
    "   4. Select the $k$ highest similarity values which are above a given threshold value, creating a collection $K$ similar users. \n",
    "   5. For each user in collection $K$, get their rating of the reference item if it exists (other users may not have rated this item as well)\n",
    "   6. Compute a weighted average rating from both the gathered rating values and user similarity values. This is expressed in the formula as: \n",
    "   \n",
    "   $$ \\hat{R}_{ju} = \\frac{\\sum_{n \\in K} s_{nu} \\times r_{nj}}{\\sum_{n \\in K} s_{nu}}   $$\n",
    "   \n",
    "   Where $\\hat{R}_{ju}$ is the weighted average computed for the reference item $j$ and reference user $u$, $K$ is the collection of similar users, $s_{nu}$ is the similarity computed between users $n$ and $u$, and $r_{nj}$ is the known rating user $n$ has given item $j$.\n",
    "   7. We return the weighted average $\\hat{R}_{ju}$ as the prediction for our reference item.\n",
    "   \n",
    "   \n",
    "We implement this algorithmic process in the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collab_generate_rating_estimate(book_title, user, k=20, threshold=0.0):\n",
    "    # Gather the k users which are most similar to the reference user \n",
    "    sim_users = user_sim_df.sort_values(by=user, ascending=False).index[1:k+1]\n",
    "    # Store the corresponding user's similarity values \n",
    "    user_values = user_sim_df.sort_values(by=user, ascending=False).loc[:,user].tolist()[1:k+1]\n",
    "    rating_list = [] # <-- List of k user's ratings for the reference item\n",
    "    weight_list = [] # <-- List of k user's similarities to the reference user\n",
    "    \n",
    "    # Create a weighted sum for each of the k users who have rated the \n",
    "    # reference item (book).\n",
    "    for sim_idx, user_id in enumerate(sim_users):\n",
    "        # User's rating of the item\n",
    "        rating = util_matrix.loc[user_id, book_title]\n",
    "        # User's similarity to the reference user \n",
    "        similarity = user_values[sim_idx]\n",
    "        # Skip the user if they have not rated the item, or are too dissimilar to \n",
    "        # the reference user\n",
    "        if (np.isnan(rating)) or (similarity < threshold):\n",
    "            continue\n",
    "        elif not np.isnan(rating):\n",
    "            rating_list.append(rating*similarity)\n",
    "            weight_list.append(similarity)\n",
    "    try:\n",
    "        # Return the weighted sum as the predicted rating for the reference item\n",
    "        predicted_rating = sum(rating_list)/sum(weight_list) \n",
    "    except ZeroDivisionError:\n",
    "        # If no ratings for the reference item can be collected, return the average \n",
    "        # rating given by all users for the item.  \n",
    "        predicted_rating = np.mean(util_matrix[book_title])\n",
    "    return predicted_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we can use our newly formed function to generate rating predictions for user 314.\n",
    "\n",
    "We start with some known ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"The Lord of the Rings: Weapons and Warfare\"\n",
    "actual_rating = book_ratings[(book_ratings['user_id'] == 314) & (book_ratings['title'] == title)]['rating'].values[0]\n",
    "pred_rating = collab_generate_rating_estimate(book_title = title, user = 314)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t {actual_rating}\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Harry Potter and the Goblet of Fire (Harry Potter, #4)\"\n",
    "actual_rating = book_ratings[(book_ratings['user_id'] == 314) & (book_ratings['title'] == title)]['rating'].values[0]\n",
    "pred_rating = collab_generate_rating_estimate(book_title = title, user = 314)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t {actual_rating}\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also two unknown ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"The Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy, #1)\"\n",
    "pred_rating = collab_generate_rating_estimate(book_title = title, user = 314)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t ?\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Treasure Island\"\n",
    "pred_rating = collab_generate_rating_estimate(book_title = title, user = 314)\n",
    "print (f\"Title - {title}\")\n",
    "print (\"---\")\n",
    "print (f\"Actual rating: \\t\\t ?\")\n",
    "print (f\"Predicted rating: \\t {pred_rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we seem to have derived some very strong results, with our predictions being very close to that of user 314's historical ratings. While again we cannot make any pronouncements on the unseen rating predictions, these values seem to make sense and align with ratings the user has given similar books. \n",
    "\n",
    "That's it for collaborative filtering!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Metric comparison: Student exercise\n",
    "Within the above sections, we implemented functions to predict item (book) ratings using both collaborative and content filtering. Using an appropriate performance metric such as RMSE or MAE, determine which of these two methods is more appropriate for the GoodBooks dataset. You could do this by:\n",
    "* Divide the book_ratings dataframe into a train and test subset using random sampling. Ensure that the train set is 90 - 95% of the total data.\n",
    "* Computing similarity matrices using the data available in the train set (this will mainly affect collaborative filtering)\n",
    "* For each user-item rating in the test set, generate a rating prediction.\n",
    "* Use the historical rating data in the test set to quantify the performance of each technique.\n",
    "\n",
    "Once you've computed these results, consider how you could improve either method to be more competitive. How feasible are these changes?\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Other considerations \n",
    "\n",
    "Here are a couple more things to take into account when implementing these methods:\n",
    "\n",
    " - **Diversity of suggestions**: As has already been observed within this train, the diversity of recommendations offered by a recommender algorithm are important. In this sense, collaborative filtering is often considered to produce superior results over content-based filtering.  \n",
    " \n",
    " \n",
    " - **Computational requirements**: While we've used simple examples to illustrate the implementation of collaborative and content-based filtering, you should not overlook considerations for the type of computational resources these methods rely upon. In this sense, both methods require the computation of similarity structures when making recommendations. For content-based filtering, this similarity structure tends to be smaller compared to its collaborative counterpart, as large recommendation services tend to have far more users than items in their databases. The storage of these similarity matrices can take up considerable space. Furthermore, the properties of items remain quite static, meaning that once the item similarity matrix is computed, it can be reused indefinitely (until more properties are used for similarity computation). On the other hand, as user ratings are added to at a constant rate, the utility matrix and, subsequently, the user similarity matrix need to be updated regularly to ensure appropriate recommendations are produced.         \n",
    "  \n",
    "  \n",
    " - **Sparsity issues**: We've briefly mentioned the Cold-start problem before within this train. To reiterate the point, due to the sparse nature of the utility matrix, it can often become very difficult to make recommendations for users who have few or no ratings captured. However, as time increases, systems that make use of collaborative filtering techniques get progressively better as they passively acquire richer rating data.  \n",
    " \n",
    " \n",
    " - **Hybrid approaches**: In light of the points raised above, one may wonder if there is a 'best of both worlds' approach for recommendation systems which overcomes the limitations of each method. The short is that there is, and this consists of hybrid content-collaborative filtering systems. These are hot research topics at the moment, with all major tech companies such as Google, Netflix, Facebook, and Amazon refining such hybrid approaches."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Phew! We've covered a lot of ground. Hopefully, at this point, the ideas behind recommender systems and why they are so economically and socially important are a bit less mystical to us. In this train, we explored the use of collaborative filtering within recommender systems and the theory behind this method. Lastly, we used the results obtained in our implementation step to discuss some trade-offs offered between content and collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix \n",
    "Links to additional resources to help with the understanding of concepts presented in the train:\n",
    "- [Overview of Collaborative Filtering](https://youtu.be/h9gpufJFF-0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
